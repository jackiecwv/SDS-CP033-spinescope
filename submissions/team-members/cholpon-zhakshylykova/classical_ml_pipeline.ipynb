{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b40a486",
   "metadata": {},
   "source": [
    "\n",
    "# Classical ML Model Development Pipeline (with MLflow)\n",
    ">  **`column_3C_processed.csv`** the scipt works with this file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6115a5",
   "metadata": {},
   "source": [
    "## 1) Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a7d428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, \n",
    "    RandomizedSearchCV, StratifiedKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import shap\n",
    "from sklearn.model_selection import learning_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from scipy import stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- ENSURE OUTPUT DIRECTORY EXISTS ---\n",
    "os.makedirs('outputs_ml', exist_ok=True)\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752098e7",
   "metadata": {},
   "source": [
    "## 2) Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d962736f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a configuration class for the model development pipeline\n",
    "class Config:\n",
    "    \"\"\"Configuration class for model development pipeline\"\"\"\n",
    "    EXPERIMENT_NAME = \"Orthopedic_Patients_Classification\"\n",
    "    MODEL_REGISTRY_NAME = \"orthopedic_classifier\"\n",
    "    RANDOM_STATE = 42\n",
    "    TEST_SIZE = 0.2\n",
    "    VALIDATION_SIZE = 0.2  # From training set\n",
    "    CV_FOLDS = 5\n",
    "    MAX_EVALS = 50  # For hyperparameter tuning\n",
    "    \n",
    "    # Class imbalance handling\n",
    "    IMBALANCE_STRATEGY = \"SMOTE\"  # Options: \"SMOTE\", \"UNDERSAMPLING\", \"SMOTEENN\", \"WEIGHTED\"\n",
    "    \n",
    "    # Linear model preprocessing\n",
    "    POWER_TRANSFORM = True  # Apply Yeo-Johnson transformation\n",
    "    VIF_THRESHOLD = 5.0  # Variance Inflation Factor threshold\n",
    "    OUTLIER_REMOVAL = True  # Remove outliers for linear models\n",
    "    \n",
    "    # MLflow tracking\n",
    "    TRACKING_URI = \"sqlite:///mlflow.db\"  # Use SQLite for local tracking\n",
    "    ARTIFACT_ROOT = \"./mlruns\"\n",
    "\n",
    "cfg = Config()\n",
    "cfg.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547a264",
   "metadata": {},
   "source": [
    "## 3) Pipeline Class — Initialization & MLflow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6352a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment: Orthopedic_Patients_Classification\n",
      "Experiment ID: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ModelDevelopmentPipeline:\n",
    "    \"\"\"Comprehensive model development pipeline with MLflow tracking\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.df = None\n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        self.y_test = None\n",
    "        self.scaler = None\n",
    "        self.standard_scaler = None\n",
    "        self.power_transformer = None\n",
    "        self.label_encoder = None\n",
    "        self.feature_names = None\n",
    "        self.selected_features = None\n",
    "        self.models_performance = {}\n",
    "        self.smote = None\n",
    "        self.outlier_mask = None\n",
    "        \n",
    "        # Setup MLflow\n",
    "        self.setup_mlflow()\n",
    "    \n",
    "    def setup_mlflow(self):\n",
    "        \"\"\"Initialize MLflow tracking\"\"\"\n",
    "        mlflow.set_tracking_uri(self.config.TRACKING_URI)\n",
    "        \n",
    "        # Create experiment if it doesn't exist\n",
    "        try:\n",
    "            experiment_id = mlflow.create_experiment(\n",
    "                name=self.config.EXPERIMENT_NAME,\n",
    "                artifact_location=self.config.ARTIFACT_ROOT\n",
    "            )\n",
    "        except mlflow.exceptions.MlflowException:\n",
    "            experiment = mlflow.get_experiment_by_name(self.config.EXPERIMENT_NAME)\n",
    "            experiment_id = experiment.experiment_id if experiment else None\n",
    "        \n",
    "        mlflow.set_experiment(self.config.EXPERIMENT_NAME)\n",
    "        print(f\"MLflow experiment: {self.config.EXPERIMENT_NAME}\")\n",
    "        print(f\"Experiment ID: {experiment_id}\")\n",
    "\n",
    "pipeline = ModelDevelopmentPipeline(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043a883",
   "metadata": {},
   "source": [
    "### 3.1 Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2cc086bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Dataset shape: (310, 8)\n",
      "Target distribution:\n",
      "binary_class\n",
      "Abnormal    210\n",
      "Normal      100\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_tilt</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>pi_ss_ratio</th>\n",
       "      <th>class</th>\n",
       "      <th>binary_class</th>\n",
       "      <th>degree_spondylolisthesis_PowerTransformer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.552586</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>1.557195</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>-0.267585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.060991</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>1.346979</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>2.922868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.218482</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>1.476653</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>-5.347396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>1.552209</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>5.581202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.652075</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>1.240936</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>4.373008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pelvic_tilt  sacral_slope  lumbar_lordosis_angle  pelvic_radius  \\\n",
       "0    22.552586     40.475232              39.609117      98.672917   \n",
       "1    10.060991     28.995960              25.015378     114.405425   \n",
       "2    22.218482     46.613539              50.092194     105.985135   \n",
       "3    24.652878     44.644130              44.311238     101.868495   \n",
       "4     9.652075     40.060784              28.317406     108.168725   \n",
       "\n",
       "   pi_ss_ratio   class binary_class  degree_spondylolisthesis_PowerTransformer  \n",
       "0     1.557195  Hernia     Abnormal                                  -0.267585  \n",
       "1     1.346979  Hernia     Abnormal                                   2.922868  \n",
       "2     1.476653  Hernia     Abnormal                                  -5.347396  \n",
       "3     1.552209  Hernia     Abnormal                                   5.581202  \n",
       "4     1.240936  Hernia     Abnormal                                   4.373008  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare the dataset\n",
    "def _mdp_load_and_prepare_data(self):\n",
    "    \"\"\"Load and prepare the dataset\"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    self.df = pd.read_csv('column_3C_processed.csv')\n",
    "    print(f\"Dataset shape: {self.df.shape}\")\n",
    "    print(f\"Target distribution:\\n{self.df['binary_class'].value_counts()}\")\n",
    "    \n",
    "    \n",
    "    with mlflow.start_run(run_name=\"data_preparation\"):\n",
    "        mlflow.log_param(\"dataset_shape\", self.df.shape)\n",
    "        mlflow.log_param(\"n_features\", len(self.df.select_dtypes(include=[np.number]).columns))\n",
    "        mlflow.log_param(\"target_classes\", list(self.df['binary_class'].unique()))\n",
    "        mlflow.log_param(\"class_distribution\", dict(self.df['binary_class'].value_counts()))\n",
    "        mlflow.log_metric(\"missing_values\", self.df.isnull().sum().sum())\n",
    "        mlflow.log_metric(\"duplicate_rows\", self.df.duplicated().sum())\n",
    "        \n",
    "        dataset_info = {\n",
    "            \"shape\": self.df.shape,\n",
    "            \"columns\": list(self.df.columns),\n",
    "            \"dtypes\": {col: str(dtype) for col, dtype in self.df.dtypes.items()},\n",
    "            \"missing_values\": self.df.isnull().sum().to_dict(),\n",
    "            \"class_distribution\": self.df['binary_class'].value_counts().to_dict()\n",
    "        }\n",
    "        with open(\"outputs_ml/dataset_info.json\", \"w\") as f:\n",
    "            json.dump(dataset_info, f, indent=2)\n",
    "        mlflow.log_artifact(\"outputs_ml/dataset_info.json\")\n",
    "        os.remove(\"outputs_ml/dataset_info.json\")\n",
    "ModelDevelopmentPipeline.load_and_prepare_data = _mdp_load_and_prepare_data\n",
    "\n",
    "pipeline.load_and_prepare_data()\n",
    "\n",
    "pipeline.df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a446b",
   "metadata": {},
   "source": [
    "### 3.2 Check Linear Model Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f5a8499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking linear model assumptions...\n",
      "  Checking multicollinearity...\n",
      "    Features with VIF > 5.0: 5\n",
      "  Checking feature normality...\n",
      "    Non-normal features: 6\n",
      "  Checking for outliers...\n",
      "    Total outliers detected: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'high_vif_features': ['pelvic_tilt',\n",
       "  'sacral_slope',\n",
       "  'lumbar_lordosis_angle',\n",
       "  'pelvic_radius',\n",
       "  'pi_ss_ratio'],\n",
       " 'vif_data':                                      Feature        VIF\n",
       " 0                                pelvic_tilt  15.641706\n",
       " 1                               sacral_slope  17.965248\n",
       " 2                      lumbar_lordosis_angle  20.399892\n",
       " 3                              pelvic_radius  54.438131\n",
       " 4                                pi_ss_ratio  65.882886\n",
       " 5  degree_spondylolisthesis_PowerTransformer   2.925936,\n",
       " 'non_normal_features': ['pelvic_tilt',\n",
       "  'sacral_slope',\n",
       "  'lumbar_lordosis_angle',\n",
       "  'pelvic_radius',\n",
       "  'pi_ss_ratio',\n",
       "  'degree_spondylolisthesis_PowerTransformer'],\n",
       " 'normality_results': {'pelvic_tilt': {'statistic': 0.9663857998124333,\n",
       "   'p_value': 1.320714460490842e-06,\n",
       "   'is_normal': False},\n",
       "  'sacral_slope': {'statistic': 0.9639800182045095,\n",
       "   'p_value': 5.886692035435651e-07,\n",
       "   'is_normal': False},\n",
       "  'lumbar_lordosis_angle': {'statistic': 0.9718123872896038,\n",
       "   'p_value': 9.221201776328966e-06,\n",
       "   'is_normal': False},\n",
       "  'pelvic_radius': {'statistic': 0.9887216793605672,\n",
       "   'p_value': 0.016610386546881496,\n",
       "   'is_normal': False},\n",
       "  'pi_ss_ratio': {'statistic': 0.8614090897444494,\n",
       "   'p_value': 4.980829696148075e-16,\n",
       "   'is_normal': False},\n",
       "  'degree_spondylolisthesis_PowerTransformer': {'statistic': 0.968431024511802,\n",
       "   'p_value': 2.6910560180362004e-06,\n",
       "   'is_normal': False}},\n",
       " 'outlier_counts': {'pelvic_tilt': 13,\n",
       "  'sacral_slope': 1,\n",
       "  'lumbar_lordosis_angle': 1,\n",
       "  'pelvic_radius': 11,\n",
       "  'pi_ss_ratio': 16,\n",
       "  'degree_spondylolisthesis_PowerTransformer': 6}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check linear model assumptions: multicollinearity - VIF , normality - shapiro test, outliers - Quantile method\n",
    "def _mdp_check_linear_model_assumptions(self, X, y):\n",
    "    print(\"Checking linear model assumptions...\")\n",
    "    assumptions_results = {}\n",
    "    # VIF\n",
    "    print(\"  Checking multicollinearity...\")\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    high_vif_features = vif_data[vif_data[\"VIF\"] > self.config.VIF_THRESHOLD][\"Feature\"].tolist()\n",
    "    assumptions_results[\"high_vif_features\"] = high_vif_features\n",
    "    assumptions_results[\"vif_data\"] = vif_data\n",
    "    print(f\"    Features with VIF > {self.config.VIF_THRESHOLD}: {len(high_vif_features)}\")\n",
    "    # Normality\n",
    "    print(\"  Checking feature normality...\")\n",
    "    normality_results = {}\n",
    "    for col in X.columns:\n",
    "        stat, p_value = stats.shapiro(X[col])\n",
    "        normality_results[col] = {\"statistic\": float(stat), \"p_value\": float(p_value), \"is_normal\": bool(p_value > 0.05)}\n",
    "    non_normal_features = [col for col, r in normality_results.items() if not r[\"is_normal\"]]\n",
    "    assumptions_results[\"non_normal_features\"] = non_normal_features\n",
    "    assumptions_results[\"normality_results\"] = normality_results\n",
    "    print(f\"    Non-normal features: {len(non_normal_features)}\")\n",
    "    # Outliers\n",
    "    print(\"  Checking for outliers...\")\n",
    "    outlier_counts = {}\n",
    "    for col in X.columns:\n",
    "        Q1, Q3 = X[col].quantile(0.25), X[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lb, ub = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "        outliers = ((X[col] < lb) | (X[col] > ub)).sum()\n",
    "        outlier_counts[col] = int(outliers)\n",
    "    assumptions_results[\"outlier_counts\"] = outlier_counts\n",
    "    total_outliers = sum(outlier_counts.values())\n",
    "    print(f\"    Total outliers detected: {total_outliers}\")\n",
    "    # Save summaries\n",
    "    vif_data.to_csv(\"outputs_ml/vif_data.csv\", index=False)\n",
    "    with open(\"outputs_ml/normality_results.json\", \"w\") as f: json.dump(normality_results, f, indent=2)\n",
    "    with open(\"outputs_ml/outlier_counts.json\", \"w\") as f: json.dump(outlier_counts, f, indent=2)\n",
    "    return assumptions_results\n",
    "ModelDevelopmentPipeline.check_linear_model_assumptions = _mdp_check_linear_model_assumptions\n",
    "X = pipeline.df.drop(columns=['binary_class', 'class'])\n",
    "y = pipeline.df['binary_class']\n",
    "pipeline.check_linear_model_assumptions(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc762cc",
   "metadata": {},
   "source": [
    "### 3.3 Apply Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94dd1b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _mdp_apply_transformations(self, X_train, X_val, X_test, for_linear_models=False):\n",
    "    print(\"Applying data transformations...\")\n",
    "    X_train_t = X_train.copy(); X_val_t = X_val.copy(); X_test_t = X_test.copy()\n",
    "\n",
    "    if for_linear_models:\n",
    "        print(\"  Applying standard scaling to all columns...\")\n",
    "        self.standard_scaler = StandardScaler() # For linear models, we use StandardScaler\n",
    "        X_train_t = pd.DataFrame(self.standard_scaler.fit_transform(X_train_t), columns=X_train_t.columns, index=X_train_t.index)\n",
    "        X_val_t   = pd.DataFrame(self.standard_scaler.transform(X_val_t), columns=X_val_t.columns, index=X_val_t.index)\n",
    "        X_test_t  = pd.DataFrame(self.standard_scaler.transform(X_test_t), columns=X_test_t.columns, index=X_test_t.index)\n",
    "        print(\"  Applying feature selection...\")\n",
    "        k_best = min(len(X_train_t.columns) - 1, 6) # Limit to 4 features for linear models\n",
    "        selector = SelectKBest(score_func=f_classif, k=k_best) # Select top k features based on ANOVA F-value\n",
    "        X_train_t = selector.fit_transform(X_train_t, self.y_train)\n",
    "        X_val_t   = selector.transform(X_val_t)\n",
    "        X_test_t  = selector.transform(X_test_t)\n",
    "        self.selected_features = [self.feature_names[i] for i in selector.get_support(indices=True)]\n",
    "        print(f\"    Selected features: {self.selected_features}\")\n",
    "    else:\n",
    "        print(\"  Applying standard scaling to all columns...\")\n",
    "        self.scaler = StandardScaler()\n",
    "        X_train_t = self.scaler.fit_transform(X_train_t)\n",
    "        X_val_t   = self.scaler.transform(X_val_t)\n",
    "        X_test_t  = self.scaler.transform(X_test_t)\n",
    "    return X_train_t, X_val_t, X_test_t\n",
    "ModelDevelopmentPipeline.apply_transformations = _mdp_apply_transformations\n",
    "\n",
    "print(pipeline.selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c15233",
   "metadata": {},
   "source": [
    "### 3.4 Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e2f5f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _mdp_handle_class_imbalance(self, X_train, y_train):\n",
    "    print(f\"Handling class imbalance using {self.config.IMBALANCE_STRATEGY}...\")\n",
    "    print(\"  Original distribution:\", dict(pd.Series(y_train).value_counts().sort_index()))\n",
    "    X_res, y_res = X_train, y_train\n",
    "    if self.config.IMBALANCE_STRATEGY == \"SMOTE\":\n",
    "        self.smote = SMOTE(random_state=self.config.RANDOM_STATE)\n",
    "        X_res, y_res = self.smote.fit_resample(X_train, y_train)\n",
    "    elif self.config.IMBALANCE_STRATEGY == \"UNDERSAMPLING\":\n",
    "        rus = RandomUnderSampler(random_state=self.config.RANDOM_STATE)\n",
    "        X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "    elif self.config.IMBALANCE_STRATEGY == \"SMOTEENN\":\n",
    "        smote_enn = SMOTEENN(random_state=self.config.RANDOM_STATE)\n",
    "        X_res, y_res = smote_enn.fit_resample(X_train, y_train)\n",
    "    elif self.config.IMBALANCE_STRATEGY == \"WEIGHTED\":\n",
    "        print(\"  Using class weights in models...\")\n",
    "        return X_train, y_train\n",
    "    print(\"  New distribution:\", dict(pd.Series(y_res).value_counts().sort_index()))\n",
    "    return X_res, y_res\n",
    "ModelDevelopmentPipeline.handle_class_imbalance = _mdp_handle_class_imbalance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d8143f",
   "metadata": {},
   "source": [
    "### 3.5 Split & Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3b0b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _mdp_split_and_scale_data(self, target_col='binary_class'):\n",
    "    print(\"Splitting and scaling data...\")\n",
    "    numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    X = self.df[numerical_cols]; y = self.df[target_col]\n",
    "    self.label_encoder = LabelEncoder(); y_enc = self.label_encoder.fit_transform(y)\n",
    "    self.feature_names = numerical_cols\n",
    "    X_temp, self.X_test, y_temp, self.y_test = train_test_split(\n",
    "        X, y_enc, test_size=self.config.TEST_SIZE, random_state=self.config.RANDOM_STATE, stratify=y_enc\n",
    "    )\n",
    "    val_size_adj = self.config.VALIDATION_SIZE / (1 - self.config.TEST_SIZE)\n",
    "    self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_size_adj, random_state=self.config.RANDOM_STATE, stratify=y_temp\n",
    "    )\n",
    "    print(f\"Training set: {self.X_train.shape}\")\n",
    "    print(f\"Validation set: {self.X_val.shape}\")\n",
    "    print(f\"Test set: {self.X_test.shape}\")\n",
    "    assumptions = self.check_linear_model_assumptions(self.X_train, self.y_train)\n",
    "    self.X_train_linear, self.X_val_linear, self.X_test_linear = self.apply_transformations(self.X_train, self.X_val, self.X_test, for_linear_models=True)\n",
    "    self.X_train_scaled, self.X_val_scaled, self.X_test_scaled = self.apply_transformations(self.X_train, self.X_val, self.X_test, for_linear_models=False)\n",
    "    self.X_train_balanced, self.y_train_balanced = self.handle_class_imbalance(self.X_train_scaled, self.y_train)\n",
    "    self.X_train_linear_balanced, self.y_train_linear_balanced = self.handle_class_imbalance(self.X_train_linear, self.y_train)\n",
    "    with mlflow.start_run(run_name=\"data_splitting\"):\n",
    "        mlflow.log_param(\"train_size\", len(self.X_train))\n",
    "        mlflow.log_param(\"val_size\", len(self.X_val))\n",
    "        mlflow.log_param(\"test_size\", len(self.X_test))\n",
    "        mlflow.log_param(\"n_features\", len(self.feature_names))\n",
    "        mlflow.log_param(\"feature_names\", self.feature_names)\n",
    "        mlflow.log_param(\"target_encoding\", dict(zip(self.label_encoder.classes_, self.label_encoder.transform(self.label_encoder.classes_))))\n",
    "        mlflow.log_param(\"imbalance_strategy\", self.config.IMBALANCE_STRATEGY)\n",
    "        mlflow.log_param(\"power_transform\", self.config.POWER_TRANSFORM)\n",
    "        mlflow.log_param(\"vif_threshold\", self.config.VIF_THRESHOLD)\n",
    "        mlflow.log_param(\"high_vif_features\", assumptions[\"high_vif_features\"])\n",
    "        mlflow.log_param(\"non_normal_features\", assumptions[\"non_normal_features\"])\n",
    "        mlflow.log_metric(\"total_outliers\", sum(assumptions[\"outlier_counts\"].values()))\n",
    "        mlflow.log_metric(\"balanced_train_size\", len(self.X_train_balanced))\n",
    "        if self.selected_features:\n",
    "            mlflow.log_param(\"selected_features\", self.selected_features)\n",
    "ModelDevelopmentPipeline.split_and_scale_data = _mdp_split_and_scale_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1889311",
   "metadata": {},
   "source": [
    "### 3.6 Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b2f7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _mdp_get_model_configurations(self) -> Dict[str, Dict]:\n",
    "    use_class_weights = self.config.IMBALANCE_STRATEGY == \"WEIGHTED\"\n",
    "    return {\n",
    "        'logistic_regression': {\n",
    "            'model': LogisticRegression(random_state=self.config.RANDOM_STATE, max_iter=2000), #  increased max_iter for convergence\n",
    "            'params': {\n",
    "                'C': [0.001, 0.01, 0.1, 1, 10, 100], # regularization strength\n",
    "                'penalty': ['l1', 'l2', 'elasticnet'], # regularization type\n",
    "                'solver': ['liblinear', 'saga'], #  solvers that support l1 and elasticnet\n",
    "                'class_weight': ['balanced'] if use_class_weights else [None, 'balanced'] # class weights\n",
    "            },\n",
    "            'is_linear': True\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'model': RandomForestClassifier(random_state=self.config.RANDOM_STATE),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 200, 300], # number of trees\n",
    "                'max_depth': [None, 10, 20, 30], # maximum depth of trees\n",
    "                'min_samples_split': [2, 5, 10], # minimum samples required to split an internal node\n",
    "                'min_samples_leaf': [1, 2, 4], # minimum samples required to be at a leaf node\n",
    "                'max_features': ['sqrt', 'log2', None], # maximum number of features to consider when looking for the best split\n",
    "                'class_weight': ['balanced'] if use_class_weights else [None, 'balanced'] # class weights\n",
    "            },\n",
    "            'is_linear': False\n",
    "        },\n",
    "        'gradient_boosting': {\n",
    "            'model': GradientBoostingClassifier(random_state=self.config.RANDOM_STATE),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 200, 300], # number of boosting stages to be run\n",
    "                'learning_rate': [0.01, 0.1, 0.2], # learning rate shrinks the contribution of each tree\n",
    "                'max_depth': [3, 5, 7], # maximum depth of the individual regression estimators\n",
    "                'min_samples_split': [2, 5, 10], # minimum number of samples required to split an internal node\n",
    "                'min_samples_leaf': [1, 2, 4], # minimum number of samples required to be at a leaf node\n",
    "                'subsample': [0.8, 0.9, 1.0] # fraction of samples to be used for fitting the individual base learners\n",
    "            },\n",
    "            'is_linear': False # Gradient Boosting is not a linear model\n",
    "        },\n",
    "        'svm': {\n",
    "            'model': SVC(random_state=self.config.RANDOM_STATE, probability=True), # probability=True for ROC/AUC\n",
    "            'params': {\n",
    "                'C': [0.1, 1, 10, 100], # regularization parameter\n",
    "                'kernel': ['rbf', 'poly', 'linear'], #  \n",
    "                'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1], # kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "                'class_weight': ['balanced'] if use_class_weights else [None, 'balanced'] # \n",
    "            },\n",
    "            'is_linear': True\n",
    "        },\n",
    "        'naive_bayes': {\n",
    "            'model': GaussianNB(), # Gaussian Naive Bayes\n",
    "            'params': {\n",
    "                'var_smoothing': np.logspace(-10, -6, 10) #  variance smoothing parameter\n",
    "            },\n",
    "            'is_linear': True\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeClassifier(random_state=self.config.RANDOM_STATE),\n",
    "            'params': {\n",
    "                'max_depth': [None, 5, 10, 15, 20], #  maximum depth of the tree\n",
    "                'min_samples_split': [2, 5, 10, 20], # minimum number of samples required to split an internal node\n",
    "                'min_samples_leaf': [1, 2, 5, 10], # minimum number of samples required to be at a leaf node\n",
    "                'max_features': ['sqrt', 'log2', None], # maximum number of features to consider when looking for the best split\n",
    "                'class_weight': ['balanced'] if use_class_weights else [None, 'balanced'] # class weights\n",
    "            },\n",
    "            'is_linear': False\n",
    "        },\n",
    "        'knn': {\n",
    "            'model': KNeighborsClassifier(),\n",
    "            'params': {\n",
    "                'n_neighbors': [3, 5, 7, 9, 11, 15], # number of neighbors to use\n",
    "                'weights': ['uniform', 'distance'], #   weighting function used in prediction\n",
    "                'metric': ['euclidean', 'manhattan', 'minkowski'] # distance metric\n",
    "            },\n",
    "            'is_linear': False\n",
    "        },\n",
    "    }\n",
    "ModelDevelopmentPipeline.get_model_configurations = _mdp_get_model_configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b4a91",
   "metadata": {},
   "source": [
    "### 3.7 Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "385b2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _mdp_evaluate_model(self, model, X_test, y_test, model_name: str) -> Dict[str, float]:\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'f1_score': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'precision_macro': precision_score(y_test, y_pred, average='macro'),\n",
    "        'recall_macro': recall_score(y_test, y_pred, average='macro'),\n",
    "        'f1_macro': f1_score(y_test, y_pred, average='macro'),\n",
    "    }\n",
    "    if y_prob is not None:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_test, y_prob)\n",
    "        metrics['avg_precision'] = average_precision_score(y_test, y_prob)\n",
    "    cv_scores = cross_val_score(model, X_test, y_test, cv=self.config.CV_FOLDS, scoring='accuracy')\n",
    "    metrics['cv_accuracy_mean'] = cv_scores.mean()\n",
    "    metrics['cv_accuracy_std'] = cv_scores.std()\n",
    "    return metrics\n",
    "ModelDevelopmentPipeline.evaluate_model = _mdp_evaluate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac36655",
   "metadata": {},
   "source": [
    "### 3.8 Create Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3630124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _mdp_create_evaluation_plots(self, model, X_test, y_test, model_name: str, feature_names: List[str]):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])\n",
    "    axes[0, 0].set_title(f'Confusion Matrix - {model_name}')\n",
    "    axes[0, 0].set_ylabel('True Label')\n",
    "    axes[0, 0].set_xlabel('Predicted Label')\n",
    "    if y_prob is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        auc_score = roc_auc_score(y_test, y_prob)\n",
    "        axes[0, 1].plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.3f})')\n",
    "        axes[0, 1].plot([0, 1], [0, 1], 'k--')\n",
    "        axes[0, 1].set_xlabel('False Positive Rate')\n",
    "        axes[0, 1].set_ylabel('True Positive Rate')\n",
    "        axes[0, 1].set_title(f'ROC Curve - {model_name}')\n",
    "        axes[0, 1].legend()\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "        avg_precision = average_precision_score(y_test, y_prob)\n",
    "        axes[1, 0].plot(recall, precision, label=f'PR Curve (AP = {avg_precision:.3f})')\n",
    "        axes[1, 0].set_xlabel('Recall')\n",
    "        axes[1, 0].set_ylabel('Precision')\n",
    "        axes[1, 0].set_title(f'Precision-Recall Curve - {model_name}')\n",
    "        axes[1, 0].legend()\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({'feature': feature_names,'importance': model.feature_importances_}).sort_values('importance', ascending=True)\n",
    "        axes[1, 1].barh(feature_importance['feature'], feature_importance['importance'])\n",
    "        axes[1, 1].set_title(f'Feature Importance - {model_name}'); axes[1, 1].set_xlabel('Importance')\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        coef_importance = pd.DataFrame({'feature': feature_names,'coefficient': np.abs(model.coef_[0])}).sort_values('coefficient', ascending=True)\n",
    "        axes[1, 1].barh(coef_importance['feature'], coef_importance['coefficient'])\n",
    "        axes[1, 1].set_title(f'Feature Coefficients - {model_name}'); axes[1, 1].set_xlabel('Absolute Coefficient')\n",
    "    plt.tight_layout()\n",
    "    out_path = f'outputs_ml/{model_name}_evaluation.png'\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight'); plt.close()\n",
    "    return out_path\n",
    "ModelDevelopmentPipeline.create_evaluation_plots = _mdp_create_evaluation_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d22838",
   "metadata": {},
   "source": [
    "### 3.9 Train & Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d3298830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _mdp_train_and_evaluate_models(self):\n",
    "    print(\"Training and evaluating models...\")\n",
    "    model_configs = self.get_model_configurations()\n",
    "    for model_name, config in model_configs.items():\n",
    "        print(f\"\\n{'='*50}\\nTraining {model_name.upper()}\\n{'='*50}\")\n",
    "        with mlflow.start_run(run_name=f\"{model_name}_training\"):\n",
    "            try:\n",
    "                mlflow.log_param(\"model_type\", model_name)\n",
    "                mlflow.log_param(\"random_state\", self.config.RANDOM_STATE)\n",
    "                mlflow.log_param(\"is_linear_model\", config.get('is_linear', False))\n",
    "                is_linear = config.get('is_linear', False)\n",
    "                if is_linear:\n",
    "                    if self.config.IMBALANCE_STRATEGY == \"WEIGHTED\":\n",
    "                        X_train_use, y_train_use = self.X_train_linear, self.y_train\n",
    "                    else:\n",
    "                        X_train_use, y_train_use = self.X_train_linear_balanced, self.y_train_linear_balanced\n",
    "                    X_val_use, X_test_use = self.X_val_linear, self.X_test_linear\n",
    "                    feature_names = self.selected_features if self.selected_features else self.feature_names\n",
    "                else:\n",
    "                    if self.config.IMBALANCE_STRATEGY == \"WEIGHTED\":\n",
    "                        X_train_use, y_train_use = self.X_train_scaled, self.y_train\n",
    "                    else:\n",
    "                        X_train_use, y_train_use = self.X_train_balanced, self.y_train_balanced\n",
    "                    X_val_use, X_test_use = self.X_val_scaled, self.X_test_scaled\n",
    "                    feature_names = self.feature_names\n",
    "                mlflow.log_param(\"data_preprocessing\", \"linear_transformed\" if is_linear else \"standard_scaled\")\n",
    "                mlflow.log_param(\"train_samples\", len(X_train_use))\n",
    "                mlflow.log_param(\"features_used\", feature_names)\n",
    "                print(\"Performing hyperparameter tuning...\")\n",
    "                search = RandomizedSearchCV(\n",
    "                    estimator=config['model'],\n",
    "                    param_distributions=config['params'],\n",
    "                    n_iter=min(self.config.MAX_EVALS, np.prod([len(v) if isinstance(v, list) else 1 for v in config['params'].values()])), \n",
    "                    cv=StratifiedKFold(n_splits=self.config.CV_FOLDS, shuffle=True, random_state=self.config.RANDOM_STATE),\n",
    "                    scoring='f1_weighted', n_jobs=-1, random_state=self.config.RANDOM_STATE, verbose=1\n",
    "                )\n",
    "                search.fit(X_train_use, y_train_use)\n",
    "                best_model = search.best_estimator_\n",
    "                mlflow.log_params(search.best_params_); mlflow.log_metric(\"best_cv_score\", search.best_score_)\n",
    "                val_metrics = self.evaluate_model(best_model, X_val_use, self.y_val, model_name)\n",
    "                for k,v in val_metrics.items(): mlflow.log_metric(f\"val_{k}\", v)\n",
    "                test_metrics = self.evaluate_model(best_model, X_test_use, self.y_test, model_name)\n",
    "                for k,v in test_metrics.items(): mlflow.log_metric(f\"test_{k}\", v)\n",
    "                self.models_performance[model_name] = {\n",
    "                    'model': best_model, 'best_params': search.best_params_,\n",
    "                    'val_metrics': val_metrics, 'test_metrics': test_metrics,\n",
    "                    'is_linear': is_linear, 'X_test_use': X_test_use, 'feature_names': feature_names\n",
    "                }\n",
    "                plot_path = self.create_evaluation_plots(best_model, X_test_use, self.y_test, model_name, feature_names)\n",
    "                mlflow.log_artifact(plot_path); os.remove(plot_path)\n",
    "                signature = infer_signature(X_train_use, y_train_use)\n",
    "                mlflow.sklearn.log_model(sk_model=best_model, artifact_path=f\"model_{model_name}\",\n",
    "                                         signature=signature, input_example=X_train_use[:5])\n",
    "                if hasattr(best_model, 'feature_importances_'):\n",
    "                    fi = pd.DataFrame({'feature': feature_names, 'importance': best_model.feature_importances_}).sort_values('importance', ascending=False)\n",
    "                    top_features = fi.head(5)['feature'].tolist()\n",
    "                    mlflow.log_param(\"top_5_features\", top_features)\n",
    "                    fi_path = f'outputs_ml/{model_name}_feature_importance.csv'\n",
    "                    fi.to_csv(fi_path, index=False); mlflow.log_artifact(fi_path); os.remove(fi_path)\n",
    "                print(f\"✓ {model_name} training completed\")\n",
    "                print(f\"  Best validation F1: {val_metrics['f1_score']:.4f}\")\n",
    "                print(f\"  Test F1: {test_metrics['f1_score']:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error training {model_name}: {str(e)}\")\n",
    "                mlflow.log_param(\"error\", str(e))\n",
    "                continue\n",
    "ModelDevelopmentPipeline.train_and_evaluate_models = _mdp_train_and_evaluate_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d2733",
   "metadata": {},
   "source": [
    "### 3.10 Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ee9df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _mdp_compare_models(self):\n",
    "    print(\"\\n\" + \"=\"*60); print(\"MODEL COMPARISON AND SELECTION\"); print(\"=\"*60)\n",
    "    with mlflow.start_run(run_name=\"model_comparison\"):\n",
    "        comparison_data = []\n",
    "        for model_name, perf in self.models_performance.items():\n",
    "            row = {\n",
    "                'Model': model_name,\n",
    "                'Val_Accuracy': perf['val_metrics']['accuracy'],\n",
    "                'Val_Precision': perf['val_metrics']['precision'],\n",
    "                'Val_Recall': perf['val_metrics']['recall'],\n",
    "                'Val_F1': perf['val_metrics']['f1_score'],\n",
    "                'Test_Accuracy': perf['test_metrics']['accuracy'],\n",
    "                'Test_Precision': perf['test_metrics']['precision'],\n",
    "                'Test_Recall': perf['test_metrics']['recall'],\n",
    "                'Test_F1': perf['test_metrics']['f1_score'],\n",
    "            }\n",
    "            if 'roc_auc' in perf['test_metrics']:\n",
    "                row['Test_ROC_AUC'] = perf['test_metrics']['roc_auc']\n",
    "            comparison_data.append(row)\n",
    "        comparison_df = pd.DataFrame(comparison_data).sort_values('Test_F1', ascending=False)\n",
    "        print(\"Model Performance Comparison:\"); print(comparison_df.round(4))\n",
    "        comp_csv_path = 'outputs_ml/model_comparison.csv'; comparison_df.to_csv(comp_csv_path, index=False); mlflow.log_artifact(comp_csv_path)\n",
    "        best_model_name = comparison_df.iloc[0]['Model']; best_model_f1 = comparison_df.iloc[0]['Test_F1']\n",
    "        mlflow.log_param(\"best_model\", best_model_name); mlflow.log_metric(\"best_model_f1\", best_model_f1)\n",
    "        print(f\"\\n🏆 Best Model: {best_model_name} (Test F1: {best_model_f1:.4f})\")\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        metrics_to_plot = ['Test_Accuracy', 'Test_Precision', 'Test_Recall', 'Test_F1']\n",
    "        for i, metric in enumerate(metrics_to_plot):\n",
    "            ax = axes[i//2, i%2]; bars = ax.bar(comparison_df['Model'], comparison_df[metric])\n",
    "            ax.set_title(f'{metric.replace(\"_\", \" \")} Comparison'); ax.set_ylabel(metric.replace(\"_\", \" \")); ax.tick_params(axis='x', rotation=45)\n",
    "            best_idx = comparison_df[metric].idxmax(); bars[list(comparison_df.index).index(best_idx)].set_color('gold')\n",
    "            for j, v in enumerate(comparison_df[metric]): ax.text(j, v + 0.005, f'{v:.3f}', ha='center', va='bottom')\n",
    "        plt.tight_layout(); comp_png_path = 'outputs_ml/model_comparison_chart.png'\n",
    "        plt.savefig(comp_png_path, dpi=300, bbox_inches='tight'); mlflow.log_artifact(comp_png_path); plt.close()\n",
    "        os.remove(comp_csv_path); os.remove(comp_png_path)\n",
    "        return best_model_name\n",
    "ModelDevelopmentPipeline.compare_models = _mdp_compare_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde3234",
   "metadata": {},
   "source": [
    "### 3.11 Advanced Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aeb65343",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _mdp_advanced_model_analysis(self, best_model_name: str):\n",
    "    print(\"\\n\" + \"=\"*60); print(f\"ADVANCED ANALYSIS - {best_model_name.upper()}\"); print(\"=\"*60)\n",
    "    best = self.models_performance[best_model_name]\n",
    "    best_model = best['model']; is_linear = best['is_linear']; X_test_use = best['X_test_use']; feature_names = best['feature_names']\n",
    "    with mlflow.start_run(run_name=f\"{best_model_name}_advanced_analysis\"):\n",
    "        print(\"Generating learning curves...\")\n",
    "        train_sizes, train_scores, val_scores = learning_curve(best_model, X_test_use, self.y_test, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_sizes, train_scores.mean(axis=1), 'o-', label='Training Score')\n",
    "        plt.plot(train_sizes, val_scores.mean(axis=1), 'o-', label='Validation Score')\n",
    "        plt.fill_between(train_sizes, train_scores.mean(axis=1) - train_scores.std(axis=1),\n",
    "                         train_scores.mean(axis=1) + train_scores.std(axis=1), alpha=0.1)\n",
    "        plt.fill_between(train_sizes, val_scores.mean(axis=1) - val_scores.std(axis=1),\n",
    "                         val_scores.mean(axis=1) + val_scores.std(axis=1), alpha=0.1)\n",
    "        plt.xlabel('Training Set Size'); plt.ylabel('Score'); plt.title(f'Learning Curves - {best_model_name}'); plt.legend(); plt.grid(True, alpha=0.3)\n",
    "        lc_path = 'outputs_ml/learning_curves.png'; plt.savefig(lc_path, dpi=300, bbox_inches='tight'); mlflow.log_artifact(lc_path); plt.close()\n",
    "        print(\"Calculating permutation importance...\")\n",
    "        perm = permutation_importance(best_model, X_test_use, self.y_test, n_repeats=10, random_state=self.config.RANDOM_STATE)\n",
    "        perm_df = pd.DataFrame({'feature': feature_names, 'importance_mean': perm.importances_mean, 'importance_std': perm.importances_std}).sort_values('importance_mean', ascending=False)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(perm_df['feature'], perm_df['importance_mean'], xerr=perm_df['importance_std'])\n",
    "        plt.xlabel('Permutation Importance'); plt.title(f'Permutation Importance - {best_model_name}'); plt.tight_layout()\n",
    "        perm_path = 'outputs_ml/permutation_importance.png'; plt.savefig(perm_path, dpi=300, bbox_inches='tight'); mlflow.log_artifact(perm_path); plt.close()\n",
    "        print(\"Analyzing model calibration...\")\n",
    "        if hasattr(best_model, 'predict_proba'):\n",
    "            from sklearn.calibration import calibration_curve\n",
    "            y_prob = best_model.predict_proba(X_test_use)[:, 1]\n",
    "            fop, mpv = calibration_curve(self.y_test, y_prob, n_bins=10)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(mpv, fop, \"s-\", label=f\"{best_model_name}\"); plt.plot([0,1],[0,1],\"k:\",label=\"Perfectly calibrated\")\n",
    "            plt.xlabel(\"Mean Predicted Probability\"); plt.ylabel(\"Fraction of Positives\"); plt.title(f'Calibration Plot - {best_model_name}')\n",
    "            plt.legend(); plt.grid(True, alpha=0.3)\n",
    "            calib_path = 'outputs_ml/calibration_plot.png'; plt.savefig(calib_path, dpi=300, bbox_inches='tight'); mlflow.log_artifact(calib_path); plt.close()\n",
    "        try:\n",
    "            print(\"Computing SHAP values...\")\n",
    "            explainer = shap.Explainer(best_model, X_test_use)\n",
    "            shap_values = explainer(X_test_use)\n",
    "            shap.summary_plot(shap_values, X_test_use, feature_names=feature_names, show=False)\n",
    "            plt.tight_layout(); shap_path = 'outputs_ml/shap_summary.png'; plt.savefig(shap_path, dpi=300, bbox_inches='tight'); mlflow.log_artifact(shap_path); plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"SHAP analysis skipped: {e}\")\n",
    "        if is_linear:\n",
    "            print(\"Validating linear model assumptions...\")\n",
    "            try:\n",
    "                y_pred = best_model.predict(X_test_use); residuals = self.y_test - y_pred\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.subplot(2,2,1); plt.scatter(y_pred, residuals, alpha=0.6); plt.axhline(0, color='r', ls='--'); plt.title('Residuals vs Fitted'); plt.xlabel('Fitted'); plt.ylabel('Residuals')\n",
    "                plt.subplot(2,2,2); stats.probplot(residuals, dist=\"norm\", plot=plt); plt.title('Q-Q Plot')\n",
    "                plt.subplot(2,2,3); plt.hist(residuals, bins=20, density=True, alpha=0.7); plt.title('Residuals Distribution'); plt.xlabel('Residuals'); plt.ylabel('Density')\n",
    "                plt.subplot(2,2,4); plt.scatter(y_pred, np.sqrt(np.abs(residuals)), alpha=0.6); plt.title('Scale-Location'); plt.xlabel('Fitted'); plt.ylabel('√|Residuals|')\n",
    "                plt.tight_layout(); lav_path = 'outputs_ml/linear_assumptions_validation.png'; plt.savefig(lav_path, dpi=300, bbox_inches='tight'); mlflow.log_artifact(lav_path); plt.close()\n",
    "                mlflow.log_metric(\"residuals_mean\", float(np.mean(residuals))); mlflow.log_metric(\"residuals_std\", float(np.std(residuals)))\n",
    "                dw_stat = durbin_watson(residuals); mlflow.log_metric(\"durbin_watson_stat\", float(dw_stat))\n",
    "                print(f\"    Residuals mean: {np.mean(residuals):.4f}\\n    Residuals std: {np.std(residuals):.4f}\\n    Durbin-Watson: {dw_stat:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Linear assumption validation skipped: {e}\")\n",
    "        print(\"Advanced analysis complete.\\n\")\n",
    "ModelDevelopmentPipeline.advanced_model_analysis = _mdp_advanced_model_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30088e20",
   "metadata": {},
   "source": [
    "## 4) Run Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "167fb5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment: Orthopedic_Patients_Classification\n",
      "Experiment ID: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelDevelopmentPipeline at 0x165014910>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Instantiate pipeline\n",
    "pipeline = ModelDevelopmentPipeline(cfg)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b7f9fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Dataset shape: (310, 8)\n",
      "Target distribution:\n",
      "binary_class\n",
      "Abnormal    210\n",
      "Normal      100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "pipeline.load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f7a94eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting and scaling data...\n",
      "Training set: (186, 6)\n",
      "Validation set: (62, 6)\n",
      "Test set: (62, 6)\n",
      "Checking linear model assumptions...\n",
      "  Checking multicollinearity...\n",
      "    Features with VIF > 5.0: 5\n",
      "  Checking feature normality...\n",
      "    Non-normal features: 6\n",
      "  Checking for outliers...\n",
      "    Total outliers detected: 42\n",
      "Applying data transformations...\n",
      "  Applying standard scaling to all columns...\n",
      "  Applying feature selection...\n",
      "    Selected features: ['pelvic_tilt', 'sacral_slope', 'lumbar_lordosis_angle', 'pelvic_radius', 'degree_spondylolisthesis_PowerTransformer']\n",
      "Applying data transformations...\n",
      "  Applying standard scaling to all columns...\n",
      "Handling class imbalance using SMOTE...\n",
      "  Original distribution: {0: np.int64(126), 1: np.int64(60)}\n",
      "  New distribution: {0: np.int64(126), 1: np.int64(126)}\n",
      "Handling class imbalance using SMOTE...\n",
      "  Original distribution: {0: np.int64(126), 1: np.int64(60)}\n",
      "  New distribution: {0: np.int64(126), 1: np.int64(126)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split & scale\n",
    "pipeline.split_and_scale_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35029647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating models...\n",
      "\n",
      "==================================================\n",
      "Training LOGISTIC_REGRESSION\n",
      "==================================================\n",
      "Performing hyperparameter tuning...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 17:32:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ logistic_regression training completed\n",
      "  Best validation F1: 0.8124\n",
      "  Test F1: 0.8127\n",
      "\n",
      "==================================================\n",
      "Training RANDOM_FOREST\n",
      "==================================================\n",
      "Performing hyperparameter tuning...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 17:32:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ random_forest training completed\n",
      "  Best validation F1: 0.8184\n",
      "  Test F1: 0.7938\n",
      "\n",
      "==================================================\n",
      "Training GRADIENT_BOOSTING\n",
      "==================================================\n",
      "Performing hyperparameter tuning...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 17:33:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ gradient_boosting training completed\n",
      "  Best validation F1: 0.8363\n",
      "  Test F1: 0.7938\n",
      "\n",
      "==================================================\n",
      "Training SVM\n",
      "==================================================\n",
      "Performing hyperparameter tuning...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 17:33:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ svm training completed\n",
      "  Best validation F1: 0.7709\n",
      "  Test F1: 0.8406\n",
      "\n",
      "==================================================\n",
      "Training NAIVE_BAYES\n",
      "==================================================\n",
      "Performing hyperparameter tuning...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 17:33:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ naive_bayes training completed\n",
      "  Best validation F1: 0.7239\n",
      "  Test F1: 0.7815\n",
      "\n",
      "==================================================\n",
      "Training DECISION_TREE\n",
      "==================================================\n",
      "Performing hyperparameter tuning...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 17:33:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ decision_tree training completed\n",
      "  Best validation F1: 0.7618\n",
      "  Test F1: 0.7596\n",
      "\n",
      "==================================================\n",
      "Training KNN\n",
      "==================================================\n",
      "Performing hyperparameter tuning...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/03 17:33:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ knn training completed\n",
      "  Best validation F1: 0.8572\n",
      "  Test F1: 0.8420\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train & evaluate models (with tuning)\n",
    "pipeline.train_and_evaluate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "34c6ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL COMPARISON AND SELECTION\n",
      "============================================================\n",
      "Model Performance Comparison:\n",
      "                 Model  Val_Accuracy  Val_Precision  Val_Recall  Val_F1  \\\n",
      "6                  knn        0.8548         0.8637      0.8548  0.8572   \n",
      "3                  svm        0.7742         0.7693      0.7742  0.7709   \n",
      "0  logistic_regression        0.8065         0.8449      0.8065  0.8124   \n",
      "1        random_forest        0.8226         0.8187      0.8226  0.8184   \n",
      "2    gradient_boosting        0.8387         0.8359      0.8387  0.8363   \n",
      "4          naive_bayes        0.7258         0.7224      0.7258  0.7239   \n",
      "5        decision_tree        0.7742         0.7667      0.7742  0.7618   \n",
      "\n",
      "   Test_Accuracy  Test_Precision  Test_Recall  Test_F1  Test_ROC_AUC  \n",
      "6         0.8387          0.8524       0.8387   0.8420        0.9214  \n",
      "3         0.8387          0.8443       0.8387   0.8406        0.9345  \n",
      "0         0.8065          0.8606       0.8065   0.8127        0.8893  \n",
      "1         0.7903          0.8009       0.7903   0.7938        0.8964  \n",
      "2         0.7903          0.8009       0.7903   0.7938        0.8988  \n",
      "4         0.7742          0.8286       0.7742   0.7815        0.8714  \n",
      "5         0.7581          0.7615       0.7581   0.7596        0.8131  \n",
      "\n",
      "🏆 Best Model: knn (Test F1: 0.8420)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'knn'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compare models\n",
    "best_model_name = pipeline.compare_models()\n",
    "best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aae0cd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ADVANCED ANALYSIS - KNN\n",
      "============================================================\n",
      "Generating learning curves...\n",
      "Calculating permutation importance...\n",
      "Analyzing model calibration...\n",
      "Computing SHAP values...\n",
      "SHAP analysis skipped: The passed model is not callable and cannot be analyzed directly with the given masker! Model: KNeighborsClassifier(metric='euclidean', n_neighbors=3, weights='distance')\n",
      "Advanced analysis complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Advanced analysis on best model\n",
    "pipeline.advanced_model_analysis(best_model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
